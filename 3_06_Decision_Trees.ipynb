{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WhiteHum/Application-security/blob/main/3_06_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAe8yAAoO2h7"
      },
      "source": [
        "# Decision Trees\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this lab we will train a Decision Tree using the same SMART status data that we have used in the previous labs.  We will measure the accuracy of that decision tree and use it as the basis of evaluation for the lab that follows.\n",
        "\n",
        "## Goals\n",
        "\n",
        "Learn how to use a Decision Tree classifier\n",
        "\n",
        " \n",
        "## Estimated Time: 30 minutes\n",
        "\n",
        "As was true with the last lab, we will once again be evaluating the data from BackBlaze.\n",
        "\n",
        "# <img src=\"../images/task.png\" width=20 height=20> Task 6.1\n",
        "\n",
        "Please copy the relevant code from the previous two labs that:\n",
        "\n",
        "* Loads the data from the first 20 files\n",
        "* Splits the labels out into a separate array\n",
        "* Converts the data and the labels to Numpy arrays\n",
        "* Eliminates NaN and other potential issues\n",
        "* Splits the data and labels into two arrays, (x, y) and (x_test, y_test) where the test data is 25% of the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkmpTYvYO2h9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def get_file_list(starting_directory=\"../data/Day 2/BackBlaze/data_Q4_2020/\"):\n",
        "    final_list = list()\n",
        "    files = os.listdir(starting_directory)\n",
        "    for file in files:\n",
        "        file_name = os.path.join(starting_directory, file)\n",
        "        if os.path.isdir(file_name):\n",
        "            final_list = final_list + get_file_list(file_name)\n",
        "        else:\n",
        "            final_list.append(file_name)\n",
        "    return final_list\n",
        "\n",
        "all_files = get_file_list()\n",
        "columns = [\n",
        "    'failure', \n",
        "    'capacity_bytes',\n",
        "    'smart_1_normalized',\n",
        "    'smart_2_normalized',\n",
        "    'smart_3_normalized',\n",
        "    'smart_4_normalized',\n",
        "    'smart_5_normalized',\n",
        "    'smart_7_normalized',\n",
        "    'smart_8_normalized',\n",
        "    'smart_9_normalized',\n",
        "    'smart_10_normalized',\n",
        "    'smart_11_normalized',\n",
        "    'smart_12_normalized',\n",
        "    'smart_13_normalized',\n",
        "    'smart_15_normalized',\n",
        "    'smart_16_normalized',\n",
        "    'smart_17_normalized',\n",
        "    'smart_18_normalized',\n",
        "    'smart_22_normalized',\n",
        "    'smart_23_normalized',\n",
        "    'smart_24_normalized',\n",
        "    'smart_168_normalized',\n",
        "    'smart_170_normalized',\n",
        "    'smart_173_normalized',\n",
        "    'smart_174_normalized',\n",
        "    'smart_175_normalized',\n",
        "    'smart_177_normalized',\n",
        "    'smart_179_normalized',\n",
        "    'smart_180_normalized',\n",
        "    'smart_181_normalized',\n",
        "    'smart_182_normalized',\n",
        "    'smart_183_normalized',\n",
        "    'smart_184_normalized',\n",
        "    'smart_187_normalized',\n",
        "    'smart_188_normalized',\n",
        "    'smart_189_normalized',\n",
        "    'smart_190_normalized',\n",
        "    'smart_191_normalized',\n",
        "    'smart_192_normalized',\n",
        "    'smart_193_normalized',\n",
        "    'smart_194_normalized',\n",
        "    'smart_195_normalized',\n",
        "    'smart_196_normalized',\n",
        "    'smart_197_normalized',\n",
        "    'smart_198_normalized',\n",
        "    'smart_199_normalized',\n",
        "    'smart_200_normalized',\n",
        "    'smart_201_normalized',\n",
        "    'smart_202_normalized',\n",
        "    'smart_206_normalized',\n",
        "    'smart_210_normalized',\n",
        "    'smart_218_normalized',\n",
        "    'smart_220_normalized',\n",
        "    'smart_222_normalized',\n",
        "    'smart_223_normalized',\n",
        "    'smart_224_normalized',\n",
        "    'smart_225_normalized',\n",
        "    'smart_226_normalized',\n",
        "    'smart_231_normalized',\n",
        "    'smart_232_normalized',\n",
        "    'smart_233_normalized',\n",
        "    'smart_234_normalized',\n",
        "    'smart_235_normalized',\n",
        "    'smart_240_normalized',\n",
        "    'smart_241_normalized',\n",
        "    'smart_242_normalized',\n",
        "    'smart_245_normalized',\n",
        "    'smart_247_normalized',\n",
        "    'smart_248_normalized',\n",
        "    'smart_250_normalized',\n",
        "    'smart_251_normalized',\n",
        "    'smart_252_normalized',\n",
        "    'smart_254_normalized',\n",
        "    'smart_255_normalized'\n",
        "]\n",
        "started = False\n",
        "for f in all_files[:20]:\n",
        "    if started:\n",
        "        new_df = pd.read_csv(f, usecols=columns)\n",
        "        df = df.append(new_df, ignore_index=True)\n",
        "    else:\n",
        "        df = pd.read_csv(f, usecols=columns)\n",
        "        started = True\n",
        "\n",
        "# Grab the labels\n",
        "labels = df['failure'].to_numpy()\n",
        "# Drop the failure column\n",
        "df.drop('failure', axis=1, inplace=True)\n",
        "\n",
        "# Convert to an array and replace NaN values\n",
        "x = df.to_numpy()\n",
        "for i in np.argwhere(np.isnan(x)):\n",
        "    x[i[0],i[1]] = 0\n",
        "\n",
        "testing_split = int(len(labels)*0.25)\n",
        "\n",
        "x_train = x[:testing_split]\n",
        "y_train = labels[:testing_split]\n",
        "x_test = x[testing_split:]\n",
        "y_test = labels[testing_split:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuke-zHfO2h-"
      },
      "source": [
        "Decision Trees are also available to us in the Scikit Learn package in the `tree` module.  After importing this module, we can access Decision Trees using the `DecisionTreeClassifier` class.  Using this class is exceptionally simple.  As with most classifiers, we need simply pass it the data and the labels, after which it will build the classifier.\n",
        "\n",
        "# <img src=\"../images/task.png\" width=20 height=20> Task 6.2\n",
        "\n",
        "The `sklearn` package includes a `tree` module that can be used to build decision trees easily.  Import the `tree` module.  Is it to instantiate a `DecisionTreeClassifer()` object and fit the model.\n",
        "\n",
        "Use the `tree.plot_tree()` function to plot the resulting classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGaoLXNXO2h_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU__5g-bO2h_"
      },
      "source": [
        "That was pretty easy!  How do we use the classifier?  using the same `predict()` pattern that we have seen with others.\n",
        "\n",
        "# <img src=\"../images/task.png\" width=20 height=20> Task 6.3\n",
        "\n",
        "Use the tree that you have created to `predict()` the test data.  What is the accuracy of the tree?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mErHCeqbO2h_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at_LJhtLO2h_"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Decision Trees follow a very simple algorithm.  This makes building them relatively straightforward, though they can end up being quite tall.  The downside of a Decision Tree is that the decision boundary ends up being fairly hard, meaining that we may end up having mis-classifications for new data unless the new data is very similar to the training data.  In the next lab we will attempt to improve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjAfLXx9O2h_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}